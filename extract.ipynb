{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows associated with images in data-v5/test/their_test have been removed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = 'data-v5/test/_annotations.csv'\n",
    "\n",
    "# Path to the directory containing the images to exclude\n",
    "exclude_dir = 'data-v5/test/their_test'\n",
    "\n",
    "# Path to save the excluded rows\n",
    "excluded_csv = 'data-v5/test/their_test/_annotations.csv'\n",
    "\n",
    "# Get a list of image filenames (without path) in the exclude directory\n",
    "exclude_images = {os.path.basename(file) for file in os.listdir(exclude_dir)}\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Split the DataFrame into rows to keep and rows to remove\n",
    "df_to_remove = df[df['filename'].isin(exclude_images)]\n",
    "filtered_df = df[~df['filename'].isin(exclude_images)]\n",
    "\n",
    "# Save the filtered DataFrame back to the CSV file\n",
    "filtered_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Save the removed rows into a new CSV file\n",
    "df_to_remove.to_csv(excluded_csv, index=False)\n",
    "\n",
    "print(f\"Rows associated with images in {exclude_dir} have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class pothole_id  stick_area  pothole_area\n",
      "0           1078      4165.0       27830.0\n",
      "1           1087      3358.0       37653.0\n",
      "2            113     13266.0       34452.0\n",
      "3           1137      5921.0       46438.0\n",
      "4           1143     59640.0       29892.0\n",
      "Processed data-v5/test/_annotations.csv and saved results to data-v5/test/test.csv\n",
      "class pothole_id  stick_area  pothole_area\n",
      "0           1008     12772.0      265080.0\n",
      "1           1009     21150.0       46222.0\n",
      "2            101      9690.0      181656.0\n",
      "3           1018     17820.0      240006.0\n",
      "4           1019     50400.0      214812.0\n",
      "Processed data-v5/train/_annotations.csv and saved results to data-v5/train/train.csv\n",
      "class pothole_id  stick_area  pothole_area\n",
      "0           1021      9039.0      255468.0\n",
      "1           1023     29754.0       70196.0\n",
      "2           1031     45210.0      281050.0\n",
      "3           1032      3762.0       42672.0\n",
      "4           1034      5053.0        6237.0\n",
      "Processed data-v5/valid/_annotations.csv and saved results to data-v5/valid/valid.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories to process\n",
    "directories = ['data-v5/test', 'data-v5/train', 'data-v5/valid']\n",
    "\n",
    "# Function to calculate the area of an element\n",
    "def calculate_area(row):\n",
    "    return (row['xmax'] - row['xmin']) * (row['ymax'] - row['ymin'])\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    # Load the _annotations.csv file\n",
    "    annotations_file = os.path.join(directory, '_annotations.csv')\n",
    "    df = pd.read_csv(annotations_file)\n",
    "\n",
    "   \n",
    "    \n",
    "    # Extract the pothole ID\n",
    "    df['pothole_id'] = df['filename'].str.extract(r'p(\\d+)_')[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    # Calculate the area for each class\n",
    "    df['area'] = (df['xmax'] - df['xmin']) * (df['ymax'] - df['ymin'])\n",
    "    \n",
    "    # Pivot the data to get separate columns for pothole area and stick area\n",
    "    pivot_df = df.pivot_table(index='pothole_id', columns='class', values='area', aggfunc='first').reset_index()\n",
    "    \n",
    "    # Rename the columns for clarity\n",
    "    pivot_df = pivot_df.rename(columns={'potholes': 'pothole_area', 'L': 'stick_area'})\n",
    "    print(pivot_df.head())\n",
    "    # Save the result to a new CSV file\n",
    "    output_file = os.path.join(directory, f'{os.path.basename(directory)}.csv')\n",
    "    pivot_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Processed {annotations_file} and saved results to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data-v5/test/test.csv and converted pothole areas to square millimeters.\n",
      "Processed data-v5/train/train.csv and converted pothole areas to square millimeters.\n",
      "Processed data-v5/valid/valid.csv and converted pothole areas to square millimeters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories to process\n",
    "directories = ['data-v5/test', 'data-v5/train', 'data-v5/valid']\n",
    "\n",
    "# Known dimensions of the stick in millimeters\n",
    "stick_length_mm = 500\n",
    "stick_width_mm = 4\n",
    "\n",
    "# Stick area in square millimeters\n",
    "stick_area_mm2 = stick_length_mm * stick_width_mm\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    # Load the corresponding CSV file\n",
    "    csv_file = os.path.join(directory, f'{os.path.basename(directory)}.csv')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Calculate the area of the stick in pixels (already computed in previous steps)\n",
    "    df['stick_area'] = df['stick_area'].fillna(1)  # To avoid division by zero or NaN\n",
    "    \n",
    "    # Calculate the conversion factor from pixels to mmÂ²\n",
    "    df['conversion_factor'] = stick_area_mm2 / df['stick_area']\n",
    "    \n",
    "    # Convert the pothole area to square millimeters\n",
    "    df['pothole_area_mm2'] = df['pothole_area'] * df['conversion_factor']\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Processed {csv_file} and converted pothole areas to square millimeters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-v5/test\n",
      "    pothole_id  stick_area  pothole_area  conversion_factor  pothole_area_mm2  \\\n",
      "0         1078      4165.0       27830.0           0.480192      1.336375e+04   \n",
      "1         1087      3358.0       37653.0           0.595593      2.242585e+04   \n",
      "2          113     13266.0       34452.0           0.150761      5.194030e+03   \n",
      "3         1137      5921.0       46438.0           0.337781      1.568586e+04   \n",
      "4         1143     59640.0       29892.0           0.033535      1.002414e+03   \n",
      "5         1147     18150.0       46618.0           0.110193      5.136970e+03   \n",
      "6         1154     22967.0       19448.0           0.087081      1.693560e+03   \n",
      "7          117      5346.0      135850.0           0.374111      5.082305e+04   \n",
      "8         1183     51906.0       25454.0           0.038531      9.807729e+02   \n",
      "9         1190      3140.0       37814.0           0.636943      2.408535e+04   \n",
      "10        1194      3460.0        4224.0           0.578035      2.441618e+03   \n",
      "11        1219     10951.0       34587.0           0.182632      6.316683e+03   \n",
      "12        1234      2352.0       68238.0           0.850340      5.802551e+04   \n",
      "13        1257         1.0      122094.0        2000.000000      2.441880e+08   \n",
      "14        1278     22656.0       40180.0           0.088277      3.546963e+03   \n",
      "15        1297      6216.0       41470.0           0.321750      1.334299e+04   \n",
      "16        1347      4263.0       40825.0           0.469153      1.915318e+04   \n",
      "17        1408      5952.0       83520.0           0.336022      2.806452e+04   \n",
      "18        1409      2674.0       24426.0           0.747943      1.826926e+04   \n",
      "19        1433      4972.0       29750.0           0.402253      1.196702e+04   \n",
      "20         159     12540.0       67044.0           0.159490      1.069282e+04   \n",
      "21        1592         1.0      172992.0        2000.000000      3.459840e+08   \n",
      "22        1595     15529.0      221320.0           0.128791      2.850409e+04   \n",
      "23        1597      8184.0      253685.0           0.244379      6.199536e+04   \n",
      "24        1608     28435.0      231264.0           0.070336      1.626615e+04   \n",
      "25         162     10112.0      155050.0           0.197785      3.066653e+04   \n",
      "26        1656     24108.0      212381.0           0.082960      1.761913e+04   \n",
      "27        1686     16650.0      311787.0           0.120120      3.745189e+04   \n",
      "28         189      5278.0      106586.0           0.378931      4.038878e+04   \n",
      "29        1929      7743.0      146200.0           0.258298      3.776314e+04   \n",
      "30        1971     18144.0      242248.0           0.110229      2.670282e+04   \n",
      "31        1976      7506.0      159936.0           0.266454      4.261551e+04   \n",
      "32        1988      6509.0      134088.0           0.307267      4.120080e+04   \n",
      "33        2002      6840.0      188604.0           0.292398      5.514737e+04   \n",
      "34        2006     10496.0      156933.0           0.190549      2.990339e+04   \n",
      "35        2012     10640.0       69372.0           0.187970      1.303985e+04   \n",
      "36        2013      4715.0      189924.0           0.424178      8.056161e+04   \n",
      "37         205      5046.0       63294.0           0.396354      2.508680e+04   \n",
      "38         267     10797.0      273258.0           0.185237      5.061739e+04   \n",
      "39         272     10680.0      233103.0           0.187266      4.365225e+04   \n",
      "40         299     17800.0      157182.0           0.112360      1.766090e+04   \n",
      "41         449      5452.0       99528.0           0.366838      3.651064e+04   \n",
      "42         499      2310.0       22736.0           0.865801      1.968485e+04   \n",
      "43          62      6840.0       79248.0           0.292398      2.317193e+04   \n",
      "44         924      3675.0       23240.0           0.544218      1.264762e+04   \n",
      "45         950      3906.0       84740.0           0.512033      4.338966e+04   \n",
      "46         955      8040.0       25842.0           0.248756      6.428358e+03   \n",
      "\n",
      "    Bags used _x  Bags used _y  Bags used   \n",
      "0           0.25           NaN         NaN  \n",
      "1           0.50           NaN         NaN  \n",
      "2           0.50           NaN         NaN  \n",
      "3           0.50           NaN         NaN  \n",
      "4           0.50           NaN         NaN  \n",
      "5           0.50           NaN         NaN  \n",
      "6           0.25           NaN         NaN  \n",
      "7           3.00           NaN         NaN  \n",
      "8           0.25           NaN         NaN  \n",
      "9           0.50           NaN         NaN  \n",
      "10          0.50           NaN         NaN  \n",
      "11          0.50           NaN         NaN  \n",
      "12          1.00           NaN         NaN  \n",
      "13          1.55           NaN         NaN  \n",
      "14           NaN           NaN         NaN  \n",
      "15          0.50           NaN         NaN  \n",
      "16          0.50           NaN         NaN  \n",
      "17          1.00           NaN         NaN  \n",
      "18           NaN           NaN         NaN  \n",
      "19          0.50           NaN         NaN  \n",
      "20          0.50          0.50        0.50  \n",
      "21           NaN          0.25        0.25  \n",
      "22           NaN          0.50        0.50  \n",
      "23           NaN          2.00        2.00  \n",
      "24           NaN          0.25        0.25  \n",
      "25          0.50          0.50        0.50  \n",
      "26           NaN          0.25        0.25  \n",
      "27           NaN          0.50        0.50  \n",
      "28          1.00          1.00        1.00  \n",
      "29           NaN           NaN         NaN  \n",
      "30           NaN           NaN         NaN  \n",
      "31           NaN           NaN         NaN  \n",
      "32           NaN           NaN         NaN  \n",
      "33           NaN           NaN         NaN  \n",
      "34           NaN           NaN         NaN  \n",
      "35           NaN           NaN         NaN  \n",
      "36           NaN           NaN         NaN  \n",
      "37         15.00         15.00       15.00  \n",
      "38           NaN          2.00        2.00  \n",
      "39           NaN          0.50        0.50  \n",
      "40          0.50           NaN         NaN  \n",
      "41          1.00           NaN         NaN  \n",
      "42          1.50           NaN         NaN  \n",
      "43           NaN          1.50        1.50  \n",
      "44          0.50          0.50        0.50  \n",
      "45          0.50          0.50        0.50  \n",
      "46          0.25          0.25        0.25  \n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'Bags used _x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Merge with train_labels.csv data\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpothole_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Combine 'Bags used _x' and 'Bags used _y' into 'Bags used'\u001b[39;00m\n\u001b[1;32m     26\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBags used\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBags used _x\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcombine_first(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBags used _y\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/core/reshape/merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/core/reshape/merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    837\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[1;32m    838\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[0;32m--> 840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    849\u001b[0m         join_index,\n\u001b[1;32m    850\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    856\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2757\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2755\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2758\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2760\u001b[0m     )\n\u001b[1;32m   2762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'Bags used _x'} is not allowed."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the train_labels.csv file\n",
    "train_labels_file = 'data-v5/train_labels_2.csv'\n",
    "# train_labels_file = 'data-v5/train_labels.csv'\n",
    "\n",
    "# Load the train_labels.csv file\n",
    "train_labels_df = pd.read_csv(train_labels_file)\n",
    "train_labels_df = train_labels_df.rename(columns={'Pothole number': 'pothole_id'})\n",
    "\n",
    "# Directories to process\n",
    "directories = ['data-v5/test', 'data-v5/train', 'data-v5/valid']\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    # Load the corresponding CSV file\n",
    "    csv_file = os.path.join(directory, f'{os.path.basename(directory)}.csv')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Merge with train_labels.csv data\n",
    "    merged_df = pd.merge(df, train_labels_df, how='left', on='pothole_id')\n",
    "\n",
    "    # Combine 'Bags used _x' and 'Bags used _y' into 'Bags used'\n",
    "    merged_df['Bags used'] = merged_df['Bags used _x'].combine_first(merged_df['Bags used _y'])\n",
    "\n",
    "    # Drop the now redundant 'Bags used _x' and 'Bags used _y' columns\n",
    "    merged_df = merged_df.drop(['Bags used _x', 'Bags used _y'], axis=1)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    merged_df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Processed {csv_file} and added bag usage information.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data-v5/test/test.csv and added bag usage information.\n",
      "Processed data-v5/train/train.csv and added bag usage information.\n",
      "Processed data-v5/valid/valid.csv and added bag usage information.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories to process\n",
    "directories = ['data-v5/test', 'data-v5/train', 'data-v5/valid']\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    # Load the corresponding CSV file\n",
    "    csv_file = os.path.join(directory, f'{os.path.basename(directory)}.csv')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    df = df.drop(['stick_area','pothole_area','conversion_factor'], axis=1)\n",
    "\n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print(f\"Processed {csv_file} and added bag usage information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pothole_id  stick_area  pothole_area  conversion_factor  pothole_area_mm2\n",
      "0          103        3082         52668           0.648929      34177.806619\n",
      "1          104        4095         65880           0.488400      32175.824176\n",
      "2         1040        5704         29029           0.350631      10178.471248\n",
      "3          105        4114         89516           0.486145      43517.744288\n",
      "4          108        2505        110880           0.798403      88526.946108\n",
      "5         1086        8272         39498           0.241779       9549.806576\n",
      "6         1115       14355         43362           0.139324       6041.379310\n",
      "7         1134        6426         27000           0.311236       8403.361345\n",
      "8          114        5005        105376           0.399600      42108.291708\n",
      "9         1161        5796          9090           0.345066       3136.645963\n",
      "10        1162       25654         10192           0.077961        794.573946\n",
      "11        1181        4375         39334           0.457143      17981.257143\n",
      "12        1198        4966         44164           0.402739      17786.548530\n",
      "13        1205       12480         31185           0.160256       4997.596154\n",
      "14        1250        5405         39600           0.370028      14653.098982\n",
      "15        1270        2272         34662           0.880282      30512.323944\n",
      "16        1280       22250         41474           0.089888       3728.000000\n",
      "17        1296        5083         38024           0.393468      14961.243360\n",
      "18         143        4416         33345           0.452899      15101.902174\n",
      "19        1430        5061         53000           0.395179      20944.477376\n",
      "20        1438        7890         64807           0.253485      16427.629911\n",
      "21         144        4071         39039           0.491280      19179.071481\n",
      "22         406        2100         95052           0.952381      90525.714286\n",
      "23         434        1692         46046           1.182033      54427.895981\n",
      "24         450        8100         51700           0.246914      12765.432099\n",
      "25         470        3276         45594           0.610501      27835.164835\n",
      "26         473        4623         25056           0.432620      10839.714471\n",
      "27         479        3366         83139           0.594177      49399.286988\n",
      "Processed their_test.csv and converted pothole areas to square millimeters.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file = 'their_test.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "df.drop(['stick_area',  'pothole_area',  'conversion_factor'], axis=1)\n",
    "print(df)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv('their_test.csv', index=False)\n",
    "\n",
    "print(f\"Processed {csv_file} and converted pothole areas to square millimeters.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
